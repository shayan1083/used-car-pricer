{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playwright.async_api import async_playwright\n",
    "import asyncio\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.iseecars.com/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to scrape data for one make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_data(make, model):\n",
    "    try:\n",
    "        async with async_playwright() as p:\n",
    "            # open website\n",
    "            browser = await p.chromium.launch(headless=True)\n",
    "            context = await browser.new_context()\n",
    "            page = await context.new_page()\n",
    "            await page.goto(URL, wait_until=\"networkidle\")\n",
    "            await page.wait_for_load_state(\"load\")\n",
    "            # enter car information and search\n",
    "            await page.locator('#make').select_option(make)\n",
    "            await page.locator('#model').select_option(model)\n",
    "            await page.get_by_placeholder(\"ZIP Code\").click()\n",
    "            await page.get_by_placeholder(\"ZIP Code\").press_sequentially(zip) \n",
    "            await page.get_by_role(\"button\", name=\"SEARCH\").click()\n",
    "            await page.wait_for_load_state(\"load\") \n",
    "            await asyncio.sleep(5)\n",
    "            await page.get_by_label('Radius').select_option('all')\n",
    "            # prepare excel sheet for input\n",
    "            WB = load_workbook('./CarData.xlsx')\n",
    "            WS = WB.active\n",
    "            WS.delete_rows(1, WS.max_row)\n",
    "            ymmm_string = 'year_make_model_mileage' + make\n",
    "            p_string = 'price' + model\n",
    "\n",
    "            WS.append([ymmm_string, p_string]) \n",
    "            # loop for going through the pages with car listings. will break loop when button is no longer found\n",
    "            while True:\n",
    "                # get the divs of the listings\n",
    "                car_listings = await page.locator('article.article-search-result').all()\n",
    "                # handle no cars\n",
    "                if not car_listings:\n",
    "                    print(\"No Cars Found\")\n",
    "                    break\n",
    "                # go through each div\n",
    "                for listing in car_listings:\n",
    "                    # get the information\n",
    "                    year_make_model_mileage = await listing.locator('h3 span.detailLink span').text_content(timeout=5000)\n",
    "                    price = await listing.locator('div.col3 h4').text_content(timeout=5000)\n",
    "                    # handle when price isnt in its usual location\n",
    "                    if not price:\n",
    "                        price = await listing.locator('ul.result-items').inner_text()       \n",
    "                    # add the data to the excel sheet\n",
    "                    WS.append([year_make_model_mileage, price])\n",
    "                # search for next button\n",
    "                next_button = page.get_by_text(\"Next »\")\n",
    "                # if no next button then break the loop since there are no more listings\n",
    "                if await next_button.count() == 0:\n",
    "                    break\n",
    "                # click the next button and wait for results to load\n",
    "                await page.get_by_text(\"Next »\").click()\n",
    "                await asyncio.sleep(5)\n",
    "            # save the excel\n",
    "            WB.save('./CarData.xlsx')\n",
    "            # close tab and browser\n",
    "            await page.close()\n",
    "            await browser.close()\n",
    "        print(\"done\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        WB.save('./CarData.xlsx') # when you cant press the next button anymore, error is thrown but save the file\n",
    "        print(\"done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WB = load_workbook('./CarData.xlsx')\n",
    "WS = WB.active\n",
    "WS.delete_rows(1, WS.max_row)\n",
    "WB.save('./CarData.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Processing to scrape all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makes_models = await get_car_makes_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for make, models in makes_models.items():\n",
    "    print(make)\n",
    "    for model in models:\n",
    "        print(model)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_make_model_data(browser, make, model):\n",
    "    try:\n",
    "        print(\"get_make_model_data\")\n",
    "        # open website\n",
    "        context = await browser.new_context()\n",
    "        page = await context.new_page()\n",
    "        await page.goto(URL, wait_until=\"networkidle\")\n",
    "        await page.wait_for_load_state(\"load\")\n",
    "        # enter car information and search\n",
    "        await page.locator('#make').select_option(make)\n",
    "        await page.locator('#model').select_option(model)\n",
    "        await page.get_by_placeholder(\"ZIP Code\").click()\n",
    "        await page.get_by_placeholder(\"ZIP Code\").press_sequentially('08550') \n",
    "        await page.get_by_role(\"button\", name=\"SEARCH\").click()\n",
    "        await page.wait_for_load_state(\"load\") \n",
    "        await asyncio.sleep(5)\n",
    "        await page.get_by_label('Radius').select_option('all')\n",
    "        # prepare excel file\n",
    "        WB = load_workbook('./CarData.xlsx')\n",
    "        WS = WB.active\n",
    "        print(make, \":\",model)\n",
    "        num_cars = 0\n",
    "        while num_cars<=100:\n",
    "            # get the divs of the listings\n",
    "            car_listings = await page.locator('article.article-search-result').all()\n",
    "            # handle no cars\n",
    "            if not car_listings:\n",
    "                print(\"No Cars Found\")\n",
    "                return \n",
    "            # go through each div\n",
    "            for listing in car_listings:\n",
    "                num_cars+=1\n",
    "                full_info = await listing.locator('div.additional-info-content > div > b').first.inner_text()\n",
    "                # template for each row in excel file\n",
    "                attributes_template = {\n",
    "                    \"Make:\": make,\n",
    "                    \"Model:\": model,\n",
    "                    \"Trim:\": full_info,\n",
    "                    \"Year:\": full_info,\n",
    "                    \"Location:\": None,\n",
    "                    \"Price:\": None,\n",
    "                    \"Mileage:\": None,\n",
    "                    \"Transmission:\": None,\n",
    "                    \"Exterior Color:\": None,\n",
    "                    \"Engine:\": None,\n",
    "                    \"Fuel Type:\": None,\n",
    "                    \"MPG:\": None,\n",
    "                    \"Seats:\": None,\n",
    "                    \"Drivetrain:\": None,\n",
    "                    \"VIN:\": None,\n",
    "                    \n",
    "                }\n",
    "\n",
    "                # get the information\n",
    "                info_headers = await listing.locator('div.additional-info-content-column > b').all()\n",
    "                info_values = await listing.locator('div.additional-info-content-column > span').all()\n",
    "                \n",
    "                # skip over dealer rating tag, since it doesnt have body text\n",
    "                headers = []\n",
    "                for h in info_headers:\n",
    "                    header_text = await h.inner_text()\n",
    "                    if header_text != 'Dealer Rating:':\n",
    "                        headers.append(header_text)\n",
    "\n",
    "                # fill in attributes\n",
    "                curr_car = attributes_template.copy()\n",
    "                for header,value in zip(headers,info_values):\n",
    "                    if header in attributes_template:\n",
    "                        value_text = await value.inner_text()\n",
    "                        curr_car[header] = value_text\n",
    "                new_row = []\n",
    "                for value in curr_car.values():\n",
    "                    new_row.append(value)\n",
    "                WS.append(new_row)\n",
    "            if num_cars >= 100:\n",
    "                break\n",
    "            # search for next button\n",
    "            next_button = page.get_by_text(\"Next »\")\n",
    "            # if no next button then break the loop since there are no more listings\n",
    "            if await next_button.count() == 0:\n",
    "                break\n",
    "            # click the next button and wait for results to load\n",
    "            await page.get_by_text(\"Next »\").click()\n",
    "            await asyncio.sleep(3)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"error, done\")\n",
    "    finally:\n",
    "        WB.save('./CarData.xlsx')\n",
    "        await page.close()\n",
    "        await context.close()\n",
    "        print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_all_makes_models(makes_models):\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        tasks=[]\n",
    "        for make, models in makes_models.items():\n",
    "            for model in models:\n",
    "                tasks.append(get_make_model_data(browser,make,model))\n",
    "        await asyncio.gather(*tasks)\n",
    "        await browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await scrape_all_makes_models(makes_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteratively scape all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_car_makes_models():\n",
    "    try:\n",
    "        print(\"get_car_makes_models\")\n",
    "        async with async_playwright() as p:\n",
    "            browser = await p.chromium.launch()\n",
    "            page = await browser.new_page()\n",
    "            await page.goto(URL, wait_until=\"networkidle\")\n",
    "            await page.wait_for_load_state(\"load\")\n",
    "            # extract car makes from dropdown\n",
    "            makes = await page.eval_on_selector_all(\"#make option\", \"options => options.map(option => option.textContent.trim())\")\n",
    "            makes.pop(0)\n",
    "            makes_models = {}\n",
    "            for make in makes:\n",
    "                await page.locator('#make').select_option(make)\n",
    "                models_for_make = await page.eval_on_selector_all(\"#model option\", \"options => options.map(option => option.textContent.trim())\")\n",
    "                models_for_make.pop(0)\n",
    "                makes_models[make] = models_for_make\n",
    "            \n",
    "            await page.close()\n",
    "            await browser.close()\n",
    "        print(\"done\")\n",
    "        return makes_models\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_make_model_data(browser, make, model):\n",
    "    try:\n",
    "        print(\"get_make_model_data\")\n",
    "        \n",
    "        context = await browser.new_context()\n",
    "        page = await context.new_page()\n",
    "        await page.goto(URL, wait_until=\"networkidle\")\n",
    "        await page.wait_for_load_state(\"load\")\n",
    "        # enter car information and search\n",
    "        await page.locator('#make').select_option(make)\n",
    "        await page.locator('#model').select_option(model)\n",
    "        await page.get_by_placeholder(\"ZIP Code\").click()\n",
    "        await page.get_by_placeholder(\"ZIP Code\").press_sequentially('08550') \n",
    "        await page.get_by_role(\"button\", name=\"SEARCH\").click()\n",
    "        await page.wait_for_load_state(\"load\") \n",
    "        await asyncio.sleep(3)\n",
    "        await page.get_by_label('Radius').select_option('all')\n",
    "        # prepare excel file\n",
    "        WB = load_workbook('./CarData.xlsx')\n",
    "        WS = WB.active\n",
    "        print(make, \":\",model)\n",
    "        num_cars = 0\n",
    "        while num_cars<=75:\n",
    "            # get the divs of the listings\n",
    "            car_listings = await page.locator('article.article-search-result').all()\n",
    "            # handle no cars\n",
    "            if not car_listings:\n",
    "                print(\"No Cars Found\")\n",
    "                return \n",
    "            # go through each div\n",
    "            for listing in car_listings:\n",
    "                num_cars+=1\n",
    "                full_info = await listing.locator('div.additional-info-content > div > b').first.inner_text()\n",
    "                # template for each row in excel file\n",
    "                attributes_template = {\n",
    "                    \"Make:\": make,\n",
    "                    \"Model:\": model,\n",
    "                    \"Trim:\": full_info,\n",
    "                    \"Year:\": full_info,\n",
    "                    \"Location:\": None,\n",
    "                    \"Price:\": None,\n",
    "                    \"Mileage:\": None,\n",
    "                    \"Transmission:\": None,\n",
    "                    \"Exterior Color:\": None,\n",
    "                    \"Engine:\": None,\n",
    "                    \"Fuel Type:\": None,\n",
    "                    \"MPG:\": None,\n",
    "                    \"Seats:\": None,\n",
    "                    \"Drivetrain:\": None,\n",
    "                    \"VIN:\": None,\n",
    "                    \n",
    "                }\n",
    "\n",
    "                # get the information\n",
    "                info_headers = await listing.locator('div.additional-info-content-column > b').all()\n",
    "                info_values = await listing.locator('div.additional-info-content-column > span').all()\n",
    "                \n",
    "                # skip over dealer rating tag, since it doesnt have body text\n",
    "                headers = []\n",
    "                for h in info_headers:\n",
    "                    header_text = await h.inner_text()\n",
    "                    if header_text != 'Dealer Rating:':\n",
    "                        headers.append(header_text)\n",
    "\n",
    "                # fill in attributes\n",
    "                curr_car = attributes_template.copy()\n",
    "                for header,value in zip(headers,info_values):\n",
    "                    if header in attributes_template:\n",
    "                        value_text = await value.inner_text()\n",
    "                        curr_car[header] = value_text\n",
    "                new_row = []\n",
    "                for value in curr_car.values():\n",
    "                    new_row.append(value)\n",
    "                WS.append(new_row)\n",
    "            if num_cars >= 100:\n",
    "                break\n",
    "            # search for next button\n",
    "            next_button = page.get_by_text(\"Next »\")\n",
    "            # if no next button then break the loop since there are no more listings\n",
    "            if await next_button.count() == 0:\n",
    "                break\n",
    "            # click the next button and wait for results to load\n",
    "            await page.get_by_text(\"Next »\").click()\n",
    "            await asyncio.sleep(3)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"error, done\")\n",
    "    finally:\n",
    "        WB.save('./CarData.xlsx')\n",
    "        await page.close()\n",
    "        await context.close()\n",
    "        print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_car_makes_models\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "makes_models = await get_car_makes_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(makes_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Volvo': ['S90', 'S90 Recharge', 'V40', 'V50', 'V60', 'V60 Cross Country', 'V60 Recharge', 'V70', 'V70 R', 'V90', 'V90 Cross Country', 'XC', 'XC40', 'XC40 Recharge', 'XC60', 'XC60 Recharge', 'XC70', 'XC90', 'XC90 Recharge'], 'Yugo': ['GV']}\n"
     ]
    }
   ],
   "source": [
    "last_make = 'Volvo'\n",
    "last_model = 'S90'\n",
    "start_make_index = list(makes_models.keys()).index(last_make)\n",
    "start_model_index = makes_models[last_make].index(last_model)\n",
    "continue_scrape = {}\n",
    "continue_scrape[last_make] = makes_models[last_make][start_model_index:]\n",
    "\n",
    "for i, (make,models) in enumerate(makes_models.items()):\n",
    "    if i <= start_make_index:\n",
    "        continue\n",
    "    else:\n",
    "        continue_scrape[make]=models\n",
    "print(continue_scrape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for make, models in continue_scrape.items():\n",
    "    print(make)\n",
    "    for model in models:\n",
    "        print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current make:  Volvo\n",
      "get_make_model_data\n",
      "Volvo : S90\n",
      "done\n",
      "get_make_model_data\n",
      "Volvo : S90 Recharge\n",
      "done\n",
      "get_make_model_data\n",
      "Volvo : V40\n",
      "done\n",
      "get_make_model_data\n",
      "Volvo : V50\n",
      "done\n",
      "get_make_model_data\n",
      "Volvo : V60\n",
      "done\n",
      "get_make_model_data\n",
      "Volvo : V60 Cross Country\n",
      "done\n",
      "get_make_model_data\n",
      "Volvo : V60 Recharge\n",
      "done\n",
      "get_make_model_data\n",
      "Volvo : V70\n",
      "done\n",
      "get_make_model_data\n",
      "Volvo : V70 R\n",
      "done\n",
      "get_make_model_data\n",
      "Volvo : V90\n",
      "done\n",
      "get_make_model_data\n",
      "Volvo : V90 Cross Country\n",
      "done\n",
      "get_make_model_data\n",
      "Volvo : XC\n",
      "done\n",
      "get_make_model_data\n",
      "Volvo : XC40\n",
      "done\n",
      "get_make_model_data\n",
      "Volvo : XC40 Recharge\n",
      "done\n",
      "get_make_model_data\n",
      "Volvo : XC60\n",
      "done\n",
      "get_make_model_data\n",
      "Volvo : XC60 Recharge\n",
      "done\n",
      "get_make_model_data\n",
      "Volvo : XC70\n",
      "done\n",
      "get_make_model_data\n",
      "Volvo : XC90\n",
      "done\n",
      "get_make_model_data\n",
      "Volvo : XC90 Recharge\n",
      "done\n",
      "current make:  Yugo\n",
      "get_make_model_data\n",
      "Yugo : GV\n",
      "No Cars Found\n",
      "done\n",
      "finished with all scraping\n"
     ]
    }
   ],
   "source": [
    "for make,models in continue_scrape.items():\n",
    "    try:\n",
    "        async with async_playwright() as p:\n",
    "            # open website\n",
    "            browser = await p.chromium.launch(headless=True)\n",
    "            print(\"current make: \", make)\n",
    "            for model in models:\n",
    "                await get_make_model_data(browser, make,model)  \n",
    "                #print(model)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"error, continue\")\n",
    "        continue\n",
    "    finally:\n",
    "        await browser.close()\n",
    "    \n",
    "print(\"finished with all scraping\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
